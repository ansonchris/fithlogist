
The regression code provides a series of logistic regression modeling tools, including standard logistic regression, small‑sample logistic regression, and stepwise logistic regression methods.

1)The standard logistic regression:
Application Scenarios: Suitable for regular binary logistic regression modeling scenarios with sufficient sample size (sample size ≥ 100 is recommended). 
IImplementation Method: mplemented based on the sm.Logit function in Python's statsmodels library. An intercept term is automatically generated during modeling and named ‘const’ by default to ensure the standardization of model estimation.
Examples:
Parameters:
df(pd.DataFrame): The input dataset used for logistic regression modeling.
bad_flag(str): Name of the dependent variable (Y variable) in the dataset.
label(list[str]) : List of names of independent variables (X variables) to be used in the regression analysis.
firth(bool): Indicates whether to perform small-sample logistic regression (Firth regression). This parameter is set to False in this implementation.
Properties:
result: Summarized regression results, which represent the core output we need for analysis and interpretation.
model: The native output object generated by sm.Logit from the statsmodels library, which is also returned as part of the toolkit's outputs for further custom analysis. Just for reference.
AR: Accurary ratio
summary(): Outputs overall model statistical information, including likelihood ratio test, AIC/BIC, coefficients and significance of each variable, etc.
pvalues(): Returns the p-values of each independent variable (including the intercept term const)
bse: Attribute that returns the standard errors of regression coefficients of each variable, reflecting the stability of coefficient estimation
pvalues: The two-tailed p values for the t-stats of the params.
params: Attribute that returns the regression coefficients of each variable.

2)Small-Sample Logistic Regression
Application Scenarios: Suitable for scenarios with small sample sizes (sample size <50), separation of the dependent variable (some variables completely distinguish the categories of the dependent variable), or unstable estimation of regular logistic regression (e.g., excessively large standard errors of coefficients, abnormal p-values)—such as rare event prediction, small-scale survey data modeling, etc.
Core Logic:

Implementation Method: Optimized and developed based on the core logic of the third-party firthlogist package, solving the Python version dependency and third-party library compatibility issues of the original package. Meanwhile, the model fitting (fit) process is modified to make the result calling interface completely consistent with basic logistic regression, reducing the cost of cross-module usage.
Parameters:

Properties:
The interface is fully aligned with basic logistic regression.

3)Stepwise Regression (Variable Selection Module)
Suitable for automatically variable selection through statistical criteria. It supports three modes: forward selection, backward elimination, and stepwise selection.
Core Logic:
(1) Forward Selection Process
1.Initialize an empty model (containing only the intercept term);
2.Iterate through all candidate independent variables and calculate the Score Wald Chi-Square statistic for each variable after being added to the model;
3.Select the variable with the largest Score Wald Chi-Square (corresponding to the smallest p-value) as the candidate variable;
4.If the p-value of the candidate variable is less than the user-defined entry threshold (entry_p), add it to the model; otherwise, no new variable is added;
5.Repeat steps 2-4 until no new variable meets the entry criteria, and the selection stops.
(2) Backward Elimination Process
1.Initialize a full model (containing all candidate independent variables and the intercept term);
2.Calculate the Wald Chi-Square statistic for all independent variables in the model;
3.Select the variable with the smallest Wald Chi-Square (corresponding to the largest p-value) as the candidate variable for elimination;
4.If the p-value of the candidate elimination variable is greater than the user-defined removal threshold (remove_p), delete it from the model; otherwise, no variable is eliminated;
5.Repeat steps 2-4 until no variable meets the elimination criteria, and the selection stops.
(3) Stepwise Selection Process
1.First perform 1 round of forward selection (add variables according to the entry threshold);
2.Then perform 1 round of backward elimination (delete variables according to the removal threshold);
3.Repeat the cycle of "forward selection - backward elimination". If no new variable is added and no variable is eliminated in a certain loop, the selection stops;
4.Output the finally retained variable set and the corresponding model results.

Parameters:
mode: Selection mode: forward selection/backward elimination/bidirectional selection
entry_p: Independent variable entry threshold; variables with p-values lower than this threshold can be added to the model.
remove_p: Independent variable removal threshold; variables with p-values higher than this threshold will be deleted.

Outputs: 
selected_var: the variables finally selected



Notes: It is recommended to set remove_p > entry_p to avoid repeated fluctuations of variables between "addition and elimination"
